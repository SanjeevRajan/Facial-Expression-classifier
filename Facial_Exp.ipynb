{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facial_Exp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lDZ0sw35W2U1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from collections import OrderedDict\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import os\n",
        "from torch.optim import lr_scheduler\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules import batchnorm\n",
        "bs = 1\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout2d(0.1)\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64)\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout2d(0.2)\n",
        "        )\n",
        "\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128)\n",
        "        )\n",
        "        self.conv6 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout2d(0.3)\n",
        "        )\n",
        "        self.conv7 = nn.Sequential(\n",
        "            nn.Conv2d(128,256,kernel_size=4,padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Dropout2d(0.3)\n",
        "        )\n",
        "        self.conv8 = nn.Sequential(\n",
        "            nn.Conv2d(256,256,kernel_size=3,padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256)\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(256, 7)  # number of classes =7\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv8(self.conv7(self.conv6(self.conv5(self.conv4(self.conv3(self.conv2(self.conv1(x))))))))        \n",
        "        x = F.avg_pool2d(x, kernel_size=x.shape[2:])\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        x = self.fc(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "fLuBYmbXYhXL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "#         transforms.RandomCrop((256, 256), pad_if_needed=True),\n",
        "        transforms.RandomAffine(10),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "#         transforms.RandomVerticalFlip(p=0.5),\n",
        "#         transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "#         transforms.RandomGrayscale(p=0.5),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'validation': transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.ToTensor(),\n",
        "         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "\n",
        "}\n",
        "data_dir='/tmp/images/images'\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'validation']}\n",
        "dataloders={x: torch.utils.data.DataLoader(image_datasets[x],batch_size=64,shuffle=True,num_workers=5)\n",
        "            for x in['train','validation']}\n",
        "\n",
        "dataset_size={x:len(image_datasets[x]) for x in ['train','validation']}\n",
        "class_names= image_datasets['train'].classes\n",
        "\n",
        "print(class_names)\n",
        "print(len(class_names))\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#  device=device.cuda()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZgKKNqD7sRq",
        "outputId": "ca212531-e728-4a56-97e4-54790cce7fd7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
            "7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "#         transforms.RandomCrop((256, 256), pad_if_needed=True),\n",
        "        transforms.RandomAffine(10),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "#         transforms.RandomVerticalFlip(p=0.5),\n",
        "#         transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "#         transforms.RandomGrayscale(p=0.5),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.ToTensor(),\n",
        "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'validation': transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.ToTensor(),\n",
        "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/tmp/images/images'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'validation']}\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
        "                                              shuffle =True,\n",
        "                                              num_workers=10)\n",
        "              for x in ['train', 'validation']}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "print(class_names)\n",
        "print(len(class_names))\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMSbWf_QN3_b",
        "outputId": "0d7ca0cd-5494-45b4-f8c8-3d466dd4a36a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
            "7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/Facial_Expression_Recog/archive.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "aiOb8VmAEux6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test set dogs' , len(os.listdir('/tmp/images/images/train/angry')))\n",
        "print('Test set cats' , len(os.listdir('/tmp/images/images/train/disgust')))\n",
        "print('Train set dogs' , len(os.listdir('/tmp/images/images/validation/angry')))\n",
        "print('Train set cats' , len(os.listdir('/tmp/images/images/validation/disgust')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgGdfpQhF6r7",
        "outputId": "ea2667f4-98a8-4917-fdee-7f419a22fbeb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set dogs 3993\n",
            "Test set cats 436\n",
            "Train set dogs 960\n",
            "Train set cats 111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer, num_epoch=25):\n",
        "  best_model=copy.deepcopy(model.state_dict())\n",
        "  best_Acc=0.0\n",
        "\n",
        "  for epoch in range(num_epoch):\n",
        "    print('Epoch {}/{}'.format(epoch +1 , num_epoch))\n",
        "\n",
        "    for phase in ['train','validation']:\n",
        "      if phase=='train':\n",
        "        model.train()\n",
        "      else:\n",
        "        model.test()\n",
        "      \n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0\n",
        "\n",
        "      with tqdm(dataloders[phase],unit=\"batch\") as tepoch:\n",
        "        for inputs, labels in tepoch:\n",
        "          #tepoch.set_decription(f\"Epoch{epoch}\")\n",
        "          input=inputs.to(device)\n",
        "          labels=labels.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          with torch.set_grad_enabled(phase=='train'):\n",
        "            outputs=model(inputs)\n",
        "            _, preds=torch.max(outputs,1)\n",
        "            loss=criterion(outputs,labels)\n",
        "\n",
        "            if phase=='train':\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "          \n",
        "          running_loss += loss.item()*inputs.size(0)\n",
        "          running_corrects += torch.sum(preds==labels.data)\n",
        "      \n",
        "      \n",
        "      epoch_loss=running_loss/dataset_sizes[phase]\n",
        "      epoch_acc=running_corrects.double()/dataset_sizes[phase]\n",
        "      \n",
        "      print('{} Loss : {:.4f} Acc : {:.4f}').format(phase, epoch_loss,epoch_acc)\n",
        "      \n",
        "      if epoch_acc > best:\n",
        "            best = epoch_acc\n",
        "            torch.save(model.state_dict(), \"best_2.ckpt\")\n",
        "      \n",
        "      print()\n",
        "\n",
        "  print('Best val Acc: {:4f}'.format(best))\n",
        "\n",
        "  model.load_state_dict(best_model)\n",
        "  return model"
      ],
      "metadata": {
        "id": "Q9uVqmUOuZRT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft=NeuralNet()\n",
        "model_ft=model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#criterion = nn.NLLLoss()\n",
        "\n",
        "#optimizer_ft=optim.GSD(model_ft.parameters(),lr=0.001)\n",
        "optimizer_ft=Adam(model_ft.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "\n",
        "#exp_lr_scheduler=lr_schedular.StepLR(optimizer_fr, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "083txEtWncQN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train(model_ft, criterion, optimizer_ft, num_epoch=15)"
      ],
      "metadata": {
        "id": "FRCkscjU1C4w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}